{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-couple",
   "metadata": {},
   "source": [
    "# Text Summarization\n",
    "\n",
    "텍스트 요약 기술은 긴 문장을 빠르게 파악하는데 유용합니다.\n",
    "\n",
    "## 목표\n",
    "\n",
    "- Extractive/Abstractive summarization 이해\n",
    "- 단어장 크기를 줄이는 다양한 text normalization 적용\n",
    "- seq2seq의 성능을 향상시키는 Attention Mechanism 적용\n",
    "\n",
    "\n",
    "## 텍스트 요약이란?\n",
    "\n",
    "\n",
    "긴 문서(Document) 원문을 핵심 주제만으로 구성된 짧은 요약(Summary) 문장들로 변환하는 것을 말합니다.  \n",
    "중요한 것은 요약 전후에 정보 손실 발생이 최소화되어야 한다는 점입니다.  \n",
    "텍스트 요약은 크게 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)의 두 가지 접근으로 나눌 수 있습니다.  \n",
    "\n",
    "\n",
    "### 추출적 요약 (Extractive Summarization)\n",
    "\n",
    "추출적 요약은 단어 그대로 원문에서 **문장들을 추출**해서 요약하는 방식입니다.  \n",
    "예를 들어 10개의 문장으로 구성된 텍스트가 있다면, 그중 핵심적인 문장 3개를 꺼내와서 요약문을 만듭니다.  \n",
    "하지만, 3개의 문장의 연결이 자연스럽지 않을 수 있다는 단점을 가지고 있습니다.  \n",
    "주로 전통적인 머신 러닝 방식에 속하는 텍스트 랭크(TextRank)와 같은 알고리즘을 사용합니다.\n",
    "\n",
    "[네이버 뉴스](https://news.naver.com/) 서비스에 있는 `요약봇` 기능이 대표적인 사례입니다.\n",
    "\n",
    "<img src=https://user-images.githubusercontent.com/48689553/140249527-42add3d1-cce1-447c-968d-b1594653f491.jpg width=\"700\" height=\"300\"/>\n",
    "\n",
    "\n",
    "### 추상적 요약 (Abstractive Summarization)\n",
    "\n",
    "추상적 요약은 원문으로부터 내용이 요약된 **새로운 문장을 생성**하는 것입니다.  \n",
    "원문을 구성하는 문장 중 어느 것이 요약문에 들어갈 핵심문장인지를 판단한다는 점에서 문장 분류(Text Classification) 문제로 볼 수 있습니다.  \n",
    "\n",
    "자연어 생성은 기본적으로 RNN 신경망을 사용할 수 있지만 아래와 같은 문제가 있습니다.  \n",
    "\n",
    "\n",
    "> **RNN의 한계 - `장기 의존성(long term dependencies)` 문제**  \n",
    "RNN은 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 현재에 전달하기 어렵다는 문제가 있습니다.  \n",
    "이 문제를 해결하기 위해 LSTM과 GRU가 등장했고, 이것도 부족해서 어텐션(Attention) 메커니즘이 등장했습니다.  \n",
    "\n",
    "\n",
    "구글(Google)은 이미 2016년부터 뉴스 제목을 뽑아내는 텍스트 요약 모델을 구현했습니다.  \n",
    "자세한 내용은 아래 기사를 참고하세요  \n",
    "- [구글 인공지능 \"뉴스 제목도 잘 뽑네\"](http://www.zdnet.co.kr/view/?no=20160905114833&from=Mobile)  \n",
    "\n",
    "구글은 짧은 문장. 요약문을 생성하는 모델을 딥러닝을 통해 end-to-end로 설계하도록 했습니다.  \n",
    "여기서 사용된 딥러닝 아키텍처는 **seq2seq(sequence-to-sequence)**이며 인코더와 디코더의 구조로 되어있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-myanmar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "innocent-butler",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-proof",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "liked-happiness",
   "metadata": {},
   "source": [
    "## 3. 어텐션 메커니즘 사용 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-radius",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "frozen-immigration",
   "metadata": {},
   "source": [
    "# 4. 실제 결과와 요약문 비교 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-being",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alpine-difference",
   "metadata": {},
   "source": [
    "# 5. Summa을 이용해서 추출적 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-observer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
